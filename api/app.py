from fastapi import FastAPI
from pydantic import BaseModel
from feast import FeatureStore
import mlflow.pyfunc
import pandas as pd
import os
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
from fastapi.responses import Response
import time

app = FastAPI(title="StreamFlow Churn Prediction API")

# Métriques Prometheus
REQUEST_COUNT = Counter("api_requests_total", "Total number of API requests")
REQUEST_LATENCY = Histogram("api_request_latency_seconds", "Latency of API requests in seconds")

# Config
REPO_PATH = "/repo"
# Le nom du modèle doit correspondre à celui dans MLflow
MODEL_URI = "models:/streamflow_churn/Production"

try:
    store = FeatureStore(repo_path=REPO_PATH)
    # Chargement du modèle Production au démarrage de l'API
    model = mlflow.pyfunc.load_model(MODEL_URI)
except Exception as e:
    print(f"Warning: init failed: {e}")
    store = None
    model = None

class UserPayload(BaseModel):
    user_id: str

@app.get("/health")
def health():
    return {"status": "ok"}

@app.post("/predict")
def predict(payload: UserPayload):
    # Démarrage du chrono
    start_time = time.time()
    
    # Incrémentation du compteur
    REQUEST_COUNT.inc()
    
    if store is None or model is None:
        return {"error": "Model or feature store not initialized"}

    # Liste des features Feast (doit être identique à l'entraînement)
    features_request = [
        "subs_profile_fv:months_active",
        "subs_profile_fv:monthly_fee",
        "subs_profile_fv:paperless_billing",
        "subs_profile_fv:plan_stream_tv",
        "subs_profile_fv:plan_stream_movies",
        "subs_profile_fv:net_service",
        "usage_agg_30d_fv:watch_hours_30d",
        "usage_agg_30d_fv:avg_session_mins_7d",
        "usage_agg_30d_fv:unique_devices_30d",
        "usage_agg_30d_fv:skips_7d",
        "usage_agg_30d_fv:rebuffer_events_7d",
        "payments_agg_90d_fv:failed_payments_90d",
        "support_agg_90d_fv:support_tickets_90d",
        "support_agg_90d_fv:ticket_avg_resolution_hrs_90d"
    ]

    # Récupération des features online
    feature_dict = store.get_online_features(
        features=features_request,
        entity_rows=[{"user_id": payload.user_id}],
    ).to_dict()

    X = pd.DataFrame({k: [v[0]] for k, v in feature_dict.items()})

    # Sanity check: features manquantes
    if X.isnull().any().any():
        missing = X.columns[X.isnull().any()].tolist()
        return {
            "error": f"Missing features for user_id={payload.user_id}",
            "missing_features": missing
        }

    # Nettoyage des colonnes techniques avant prédiction
    X = X.drop(columns=["user_id"], errors="ignore")
    
    # Conversion des types pour éviter les erreurs int64 vs int32
    for col in X.columns:
        if X[col].dtype == 'int64':
            X[col] = X[col].astype('int32')

    # Calcul de la prédiction
    y_pred = model.predict(X)
    
    # Mesure de la latence
    REQUEST_LATENCY.observe(time.time() - start_time)
    
    return {
        "user_id": payload.user_id,
        "prediction": int(y_pred[0]),
        "features_used": X.to_dict(orient="records")[0]
    }

@app.get("/metrics")
def metrics():
    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)